{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Bert Inference benchmarks on OpneVINO with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile question.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write benchmark commands into a file benchmark_openvino-bert_demo.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile benchmark_openvino-bert_demo.sh\n",
    "# activate opensource tf environment\n",
    "source ~/opentfov/bin/activate\n",
    "source  /opt/intel/openvino/bin/setupvars.sh\n",
    "# download OpenVINO bert IR files (.xml and .bin ) from open_model_zoo \n",
    "cd ~/oneapi_workshop\n",
    "# download FP32 files\n",
    "wget https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-large-uncased-whole-word-masking-squad-fp32-0001/FP32/bert-large-uncased-whole-word-masking-squad-fp32-0001.xml\n",
    "wget https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-large-uncased-whole-word-masking-squad-fp32-0001/FP32/bert-large-uncased-whole-word-masking-squad-fp32-0001.bin\n",
    "\n",
    "# download vocab file for words interpretation \n",
    "wget https://raw.githubusercontent.com/openvinotoolkit/open_model_zoo/master/models/intel/bert-large-uncased-whole-word-masking-squad-fp32-0001/vocab.txt\n",
    "\n",
    "# BERT demo is available in python_demos folder of openvino install path. use help to know options\n",
    "#python3 /opt/intel/openvino/deployment_tools/inference_engine/demos/python_demos/bert_question_answering_demo/bert_question_answering_demo.py -h\n",
    "\n",
    "# Run demo with proper options. A successful run will give prompt to enter qustions and after entering it will search whole text in given link and gives the answer with confidence metrics\n",
    "cat questions.txt | python3 /opt/intel/openvino/deployment_tools/inference_engine/demos/python_demos/bert_question_answering_demo/bert_question_answering_demo.py -v $HOME/oneapi_workshop/vocab.txt -m $HOME/oneapi_workshop/bert-large-uncased-whole-word-masking-squad-int8-0001.xml -i https://en.wikipedia.org/wiki/Intel --input_names \"result.1,result.2,result.3\"  --output_names 5211,5212\n",
    "# end \n",
    "    \n",
    "deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check content of benchmark_openvino-bert_demo.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat benchmark_openvino-bert_demo.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional step : Remove all old output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf benchmark_openvino-bert_demo.sh.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qsub benchmark_openvino-bert_demo.sh -l nodes=1:clx:ppn=2 -d ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the job status is finished, check the the output file with proper output name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat benchmark_openvino-bert_demo.sh.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### close the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (IntelÂ® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
